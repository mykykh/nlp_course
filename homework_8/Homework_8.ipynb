{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37eb6a53-85db-4835-8e00-ed288ae24583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mykyta/dev/study/nlp_course/homework/.poetry/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "from optimum.onnxruntime import ORTModelForTokenClassification, ORTQuantizer\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DistilBertConfig,\n",
    "    DistilBertForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f522a183-fa07-44db-8b54-f7fe116cfaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/location_detection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dcb04-75b2-49eb-bdb3-df80986193fe",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc4faea-29f0-4fe2-addb-0408bb72a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_train_processed_dataset = load_dataset(\n",
    "    'parquet',\n",
    "    data_files=DATA_DIR + 'uk_geo_dataset_processed_train_av.parquet',\n",
    "    split='train[:10%]'\n",
    ")\n",
    "uk_holdout_processed_dataset = load_dataset(\n",
    "    'parquet',\n",
    "    data_files=DATA_DIR + 'uk_geo_dataset_processed_holdout_av.parquet',\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa815ebd-2716-46b9-ad40-52aa53b02aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(DATA_DIR + 'competition/test.csv', converters={'locations': eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16857a97-2865-4f63-b1c1-a5328119be6a",
   "metadata": {},
   "source": [
    "## Roberta distilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa4367-796b-407c-b4f7-c52a048c92c2",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1211d5d-40a8-4751-99e1-06b393c66a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model_name = 'xlm-roberta-base'\n",
    "uk_checkpoint = DATA_DIR + 'models/uk-loc/checkpoint-2000'\n",
    "\n",
    "labels = ['S', 'O', 'B-LOC', 'I-LOC']\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "id2label = {i: l for i, l in enumerate(labels)}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(base_model_name, label2id=label2id, id2label=id2label)\n",
    "\n",
    "uk_model = PeftModel.from_pretrained(base_model, uk_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7c453b-4963-478a-a48b-9890e43364a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distill_config():\n",
    "    return DistilBertConfig(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        n_layers=3,\n",
    "        n_heads=6,\n",
    "        hidden_dim=1024,\n",
    "        dim=384\n",
    "    )\n",
    "\n",
    "def get_distill_base_model():\n",
    "    return DistilBertForTokenClassification(get_distill_config())\n",
    "\n",
    "distill_uk_model = get_distill_base_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dbab8-d889-41e3-b933-a524c7abf36c",
   "metadata": {},
   "source": [
    "### Align labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7359344-bd59-4dc7-a582-b966169c8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_word_ids(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "\n",
    "    for word_id in word_ids:\n",
    "        if word_id is None:\n",
    "            # special tokens\n",
    "            current_word = word_id\n",
    "            new_labels.append(label2id[\"S\"])\n",
    "        elif word_id != current_word:\n",
    "            # start of new word\n",
    "            current_word = word_id\n",
    "            new_labels.append(label2id[labels[word_id]])\n",
    "        else:\n",
    "            # part of a word\n",
    "            label = labels[word_id]\n",
    "\n",
    "            if label == \"B-LOC\":\n",
    "                label = \"I-LOC\"\n",
    "\n",
    "            new_labels.append(label2id[label])\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def align_labels(examples):\n",
    "    bert_tokens = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(examples['labels']):\n",
    "        word_ids = bert_tokens.word_ids(i)\n",
    "        new_labels.append(align_labels_with_word_ids(labels, word_ids))\n",
    "\n",
    "    bert_tokens['labels'] = new_labels\n",
    "    return bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84da2d4d-5a90-43ca-9fa8-e40a59bc0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_train_dataset = uk_train_processed_dataset.map(\n",
    "    align_labels,\n",
    "    batched=True\n",
    ")\n",
    "uk_eval_dataset = uk_holdout_processed_dataset.map(\n",
    "    align_labels,\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115ab9d-ea36-4109-a7d5-a90b9450e8f3",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92035f4c-f7c0-4c5b-a0c6-ca5a85e20189",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "  logits, labels = eval_preds\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "  true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "  prediction_label = [[id2label[p] for p, l in zip(prediction, label) if l != -100]\n",
    "                      for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "  all_metrics = metric.compute(predictions=prediction_label, references=true_labels)\n",
    "  return {\n",
    "      'precision': all_metrics['overall_precision'],\n",
    "      'recall': all_metrics['overall_recall'],\n",
    "      'f1': all_metrics['overall_f1']\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446c731-4041-4491-bbd9-51f87d3c77ac",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84775bdd-24bd-4dd6-abcb-e744175cad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillTrainer(Trainer):\n",
    "    def __init__(self, student_model, teacher_model, temperature, lambda_param, *args, **kwargs):\n",
    "        super().__init__(model=student_model, *args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.loss_fn = nn.KLDivLoss()\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.teacher.to(device)\n",
    "        self.teacher.eval()\n",
    "        self.temperature = temperature\n",
    "        self.lambda_param = lambda_param\n",
    "\n",
    "    def compute_loss(self, student, inputs, return_outputs=False):\n",
    "        student_output = self.student(**inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_output = self.teacher(**inputs)\n",
    "\n",
    "        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)\n",
    "        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n",
    "\n",
    "        # calculate loss for diference between student and teacher\n",
    "        distill_loss = self.loss_fn(soft_student, soft_teacher) * (self.temperature**2)\n",
    "\n",
    "        # loss for student target predictions\n",
    "        student_target_loss = student_output.loss\n",
    "\n",
    "        # combine student teacher loss and student target loss\n",
    "        loss = (1-self.lambda_param)*student_target_loss + self.lambda_param*distill_loss\n",
    "        \n",
    "        return (loss, student_output) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459691ba-7ca4-4fa3-9cc2-7624008bdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(output_dir, student_model, teacher_model, train_dataset, eval_dataset):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        evaluation_strategy='steps',\n",
    "        save_strategy='steps',\n",
    "        logging_strategy='steps',\n",
    "        eval_steps=100,\n",
    "        logging_steps=100,\n",
    "        save_steps=100,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "    trainer = DistillTrainer(\n",
    "        student_model=student_model,\n",
    "        teacher_model=teacher_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorForTokenClassification(tokenizer=tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        temperature=2,\n",
    "        lambda_param=0.5\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101f8a0-7b79-4827-9756-273da1469477",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    DATA_DIR + 'models/uk-distilled',\n",
    "    distill_uk_model,\n",
    "    uk_model,\n",
    "    uk_train_dataset,\n",
    "    uk_eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eaac81-3042-4125-944b-6877be92d202",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a12cb53-45be-4466-ba9c-24f5aca8f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_uk_checkpoint = DATA_DIR + 'models/uk-loc/checkpoint-2000'\n",
    "distill_uk_checkpoint = DATA_DIR + 'models/uk-distilled/checkpoint-800'\n",
    "\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(base_model_name, label2id=label2id, id2label=id2label)\n",
    "base_uk_model = PeftModel.from_pretrained(base_model, base_uk_checkpoint).merge_and_unload()\n",
    "base_uk_model.eval()\n",
    "\n",
    "distill_uk_model = DistilBertForTokenClassification.from_pretrained(distill_uk_checkpoint)\n",
    "distill_uk_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d3b2af-6c62-497a-ab7c-cd6a60a07f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_model(model, dataset):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    input = tokenizer(dataset['tokens'], return_tensors='pt', max_length=50, padding='max_length', truncation=True, is_split_into_words=True)\n",
    "    labels = [p + ([0] * (50 - len(p))) for p in [t[:50] for t in dataset['labels']]]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**input).logits.cpu().detach().numpy()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, compute_metrics((logits, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba81d6cb-3ba8-4118-8f5c-f4f389e341dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model inference time: 25.507636547088623, f1: 0.4667684195920632\n",
      "Distilled model inference time: 1.730381965637207, f1: 0.42507580565545444\n",
      "Inference acceleration: 14.74, f1 degradation: 0.04169261393660878\n"
     ]
    }
   ],
   "source": [
    "base_time, base_metrics = time_model(base_uk_model, uk_eval_dataset)\n",
    "\n",
    "distill_time, distill_metrics = time_model(distill_uk_model, uk_eval_dataset)\n",
    "\n",
    "print(f\"Original model inference time: {base_time}, f1: {base_metrics['f1']}\")\n",
    "print(f\"Distilled model inference time: {distill_time}, f1: {distill_metrics['f1']}\")\n",
    "print(f\"Inference acceleration: {round(base_time/distill_time, 2)}, f1 degradation: {base_metrics['f1'] - distill_metrics['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ec45a-f16e-4be6-bea9-8f30d61bb619",
   "metadata": {},
   "source": [
    "As we can see, distilled model is 15 times faster, but metric is only ~10% worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7f1cc-1392-4b6b-aadc-a63646f954eb",
   "metadata": {},
   "source": [
    "## Onnx conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a3b8b1-4898-43c9-9e49-5e653109f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_directory = DATA_DIR + 'models/onnx/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b8272-e431-4299-ab3b-c1ddbaafa229",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_model = ORTModelForTokenClassification.from_pretrained(distill_uk_checkpoint, export=True)\n",
    "\n",
    "ort_model.save_pretrained(onnx_directory + 'regular/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f7f633-c925-48a6-ba4b-42d6a0c4cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_uk_model = ORTModelForTokenClassification.from_pretrained(onnx_directory + 'regular/', file='model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d21015-da0f-451a-aba5-7e7edc35c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onnx model inference time: 1.6918556690216064, f1: 0.42507580565545444\n",
      "Inference acceleration: 1.02, f1 degradation: 0.0\n"
     ]
    }
   ],
   "source": [
    "onnx_time, onnx_metrics = time_model(onnx_uk_model, uk_eval_dataset)\n",
    "\n",
    "print(f\"Onnx model inference time: {onnx_time}, f1: {onnx_metrics['f1']}\")\n",
    "print(f\"Inference acceleration: {round(distill_time/onnx_time, 2)}, f1 degradation: {distill_metrics['f1'] - onnx_metrics['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d686bf-2d0f-4909-abfb-254f89235486",
   "metadata": {},
   "source": [
    "Onnx model is slower than distilled model. But since metric not degraded, using onnx model for quantization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f797c-64a5-4c2d-bca8-eda6c8192fa4",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc741d4-b8f8-42c5-9b0a-ba6dbded55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
    "quantizer = ORTQuantizer.from_pretrained(onnx_uk_model)\n",
    "\n",
    "quantizer.quantize(save_dir=onnx_directory + 'quantized/', quantization_config=qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107c6f1b-63e9-425b-b6f2-a4b16be26159",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_quant_uk_model = ORTModelForTokenClassification.from_pretrained(onnx_directory + 'quantized/', file='model_quantized.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79fcc6cc-c4eb-4fb6-aa37-83ff387a6d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qunatized model inference time: 1.4115355014801025, f1: 0.41883185840707965\n",
      "Inference acceleration: 1.23, f1 degradateion: 0.006243947248374793\n"
     ]
    }
   ],
   "source": [
    "quant_time, quant_metrics = time_model(onnx_quant_uk_model, uk_eval_dataset)\n",
    "\n",
    "print(f\"Qunatized model inference time: {quant_time}, f1: {quant_metrics['f1']}\")\n",
    "print(f\"Inference acceleration: {round(distill_time/quant_time, 2)}, f1 degradateion: {distill_metrics['f1'] - quant_metrics['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ad5cf-306f-4e00-bb62-128f0c29f30f",
   "metadata": {},
   "source": [
    "As we can see, quantized model is a little bit faster than regular distilled model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528f853-dfd5-48c8-b7d2-35c776911963",
   "metadata": {},
   "source": [
    "## FastAPI service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7061787-9049-4c67-a59c-9982d65da071",
   "metadata": {},
   "source": [
    "Code for api and docker is in ./service folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36856263-3458-4aeb-bdcf-232e6385731a",
   "metadata": {},
   "source": [
    "Predictions from distilled quantized onnx model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eedcea92-1deb-41e7-acd3-ff22c1e4e7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['–£ –ø–∞–º‚Äô—è—Ç—å –ø—Ä–æ –∑–∞–≥–∏–±–ª–æ–≥–æ –≤–∏–ø—É—Å–∫–Ω–∏–∫–∞ –ù–∞–£–ö–ú–ê –∑–±–∏—Ä–∞—é—Ç—å –∫–æ—à—Ç–∏ –Ω–∞ –º–µ–º–æ—Ä—ñ–∞–ª—å–Ω—É —Å—Ç–∏–ø–µ–Ω–¥—ñ—é\\n\\n–°—Ç–∏–ø–µ–Ω–¥—ñ—è, —è–∫—É –∑–∞—Å–Ω—É–≤–∞–ª–∏ –Ω–∞ —á–µ—Å—Ç—å –Ñ–≤–≥–µ–Ω–∞ –û–ª–µ—Ñ—ñ—Ä–µ–Ω–∫–∞, –ø–æ–∫—Ä–∏—î –ø–ª–∞—Ç—É –∑–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ —á–∏ —Å—Ç—É–¥–µ–Ω—Ç–∫–∏ –Ω–∞ –º–∞–≥—ñ—Å—Ç–µ—Ä—Å—å–∫—ñ–π –ø—Ä–æ–≥—Ä–∞–º—ñ ¬´–Ü—Å—Ç–æ—Ä—ñ—è¬ª –≤ –ú–æ–≥–∏–ª—è–Ω—Ü—ñ.\\n\\n–ù–∞ –ø–æ—á–∞—Ç–∫—É –ø–æ–≤–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –≤—Ç–æ—Ä–≥–Ω–µ–Ω–Ω—è –Ñ–≤–≥–µ–Ω –º–æ–±—ñ–ª—ñ–∑—É–≤–∞–≤—Å—è –¥–æ 206-–≥–æ –∫–∏—ó–≤—Å—å–∫–æ–≥–æ –±–∞—Ç–∞–ª—å–π–æ–Ω—É –¢—Ä–û, –±—É–≤ –∫–æ–º–∞–Ω–¥–∏—Ä–æ–º –≤–∑–≤–æ–¥—É –ü–µ—Ä—à–æ—ó –æ–∫—Ä–µ–º–æ—ó –±—Ä–∏–≥–∞–¥–∏ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è —ñ–º–µ–Ω—ñ –Ü–≤–∞–Ω–∞ –ë–æ–≥—É–Ω–∞.\\n–•–ª–æ–ø–µ—Ü—å –≤–æ—é–≤–∞–≤ –ø—ñ–¥ –ú–∏–∫–æ–ª–∞—î–≤–æ–º, –±—É–≤ –≥—Ä–∞–Ω–∞—Ç–æ–º–µ—Ç–Ω–∏–∫–æ–º —ñ –º—ñ–Ω–æ–º–µ—Ç–Ω–∏–∫–æ–º, –Ω–∞–≤—á–∞–≤ —ñ–Ω–æ–∑–µ–º–Ω–∏—Ö –¥–æ–±—Ä–æ–≤–æ–ª—å—Ü—ñ–≤. –ô–æ–≥–æ –ø—ñ–¥—Ä–æ–∑–¥—ñ–ª –∑–∞—Ö–∏—â–∞–≤ –õ–∏—Å–∏—á–∞–Ω—Å—å–∫ –Ω–∞ –õ—É–≥–∞–Ω—â–∏–Ω—ñ. –Ü –º–æ–≥–∏–ª—è–Ω–µ—Ü—å –∑—É–º—ñ–≤ –≤–∏–≤–µ—Å—Ç–∏ —Å–≤—ñ–π –≤–∑–≤–æ–¥ –∑ –Ω–∞–ø—ñ–≤–æ—Ç–æ—á–µ–Ω–æ–≥–æ –º—ñ—Å—Ç–∞ –Ω–µ—É—à–∫–æ–¥–∂–µ–Ω–∏–º. –Ñ–≤–≥–µ–Ω –∑–∞–≥–∏–Ω—É–≤ –ø—ñ–¥ –ë–∞—Ö–º—É—Ç–æ–º 7 –ª–∏–ø–Ω—è 2022 —Ä–æ–∫—É.\\n\\n–ù–∞ –∫–∞—Ñ–µ–¥—Ä—ñ —ñ—Å—Ç–æ—Ä—ñ—ó –∑–∞–∑–Ω–∞—á–∞—é—Ç—å, —â–æ –Ω–∞—Ä–∞–∑—ñ –≤–¥–∞–ª–æ—Å—å –∑—ñ–±—Ä–∞—Ç–∏ –ø–æ–≤–Ω—É —Å—É–º—É –Ω–∞ 2-–π —Ä—ñ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è, –∞ –¥–ª—è –ø–æ–≤–Ω–æ—ó —Å—Ç–∏–ø–µ–Ω–¥—ñ—ó –Ω–∞ 2023-2024 —Ä–æ–∫–∏ –±—Ä–∞–∫—É—î –ª–∏—à–µ 13 —Ç–∏—Å. –≥—Ä–Ω. –ù–µ–æ–±—Ö—ñ–¥–Ω–∞ —Å—É–º–∞: 40\\u202f000 –≥—Ä–Ω. –ó–¥—ñ–π—Å–Ω–∏—Ç–∏ –ø–µ—Ä–µ–∫–∞–∑ –º–æ–∂–Ω–∞ –∑–∞ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º. \\n\\nüî∑\\xa0–ü—ñ–¥–ø–∏—Å–∞—Ç–∏—Å—è –Ω–∞ Telegram\\xa0| Instagram\\xa0| Facebook\\xa0| TikTok',\n",
       "  'ü•∑üèª–°—Ç–æ–ª–∏—á–Ω—ñ –∫–æ–ø–∏ –≤—Ä—è—Ç—É–≤–∞–ª–∏ ¬´–ë–µ—Ç–º–µ–Ω–∞¬ª, —è–∫–∏–π –Ω–∞–º–∞–≥–∞–≤—Å—è –ø–µ—Ä–µ–ø–ª–∏—Å—Ç–∏ –î–Ω—ñ–ø—Ä–æ \\n\\n–ß–æ–ª–æ–≤—ñ–∫ –≤–∏—Ä—ñ—à–∏–≤ –¥—ñ—Å—Ç–∞—Ç–∏—Å—è –¥–æ —ñ–Ω—à–æ–≥–æ –±–µ—Ä–µ–≥–∞ —Ç–∞ –ª–µ–¥—å –Ω–µ –≤—Ç–æ–ø–∏–≤—Å—è. –ù–∞ —â–∞—Å—Ç—è, –ø–æ—Ç–µ—Ä–ø—ñ–ª–æ–≥–æ –ø–æ–º—ñ—Ç–∏–≤ –æ—á–µ–≤–∏–¥–µ—Ü—å —Ç–∞ –∑–≤–µ—Ä–Ω—É–≤—Å—è –ø–æ –¥–æ–ø–æ–º–æ–≥—É –¥–æ —Å–ø—ñ–≤—Ä–æ–±—ñ—Ç–Ω–∏–∫—ñ–≤ —Ä—ñ—á–∫–æ–≤–æ—ó –ø–æ–ª—ñ—Ü—ñ—ó.\\xa0\\n\\xa0\\n–Ü–Ω—Ü–∏–¥–µ–Ω—Ç —Ç—Ä–∞–ø–∏–≤—Å—è –≤—á–æ—Ä–∞ –≤–≤–µ—á–µ—Ä—ñ. \\n–î—ñ—Å—Ç–∞–≤—à–∏ ¬´–ë–µ—Ç–º–µ–Ω–∞¬ª –∑ –≤–æ–¥–∏ –Ω–∞ –∫–∞—Ç–µ—Ä, –ø—Ä–∞–≤–æ–æ—Ö–æ—Ä–æ–Ω—Ü—ñ –≤—Å—Ç–∞–Ω–æ–≤–∏–ª–∏ –π–æ–≥–æ –æ—Å–æ–±—É. –¶–µ - —ñ–Ω–æ–∑–µ–º–µ—Ü—å, 1995 —Ä–æ–∫—É –Ω–∞—Ä–æ–¥–∂–µ–Ω–Ω—è, —è–∫–∏–π —Ö–æ—Ç—ñ–≤ –ø–µ—Ä–µ–ø–ª–∏—Å—Ç–∏ —Ä—ñ—á–∫—É.',\n",
       "  '–£ –ö–∏—î–≤—ñ —É —à—ñ—Å—Ç—å–æ—Ö —Å–ø—ñ–≤—Ä–æ–±—ñ—Ç–Ω–∏–∫—ñ–≤ –∑–∞–∫–ª–∞–¥—É —Ö–∞—Ä—á—É–≤–∞–Ω–Ω—è –≤–∏—è–≤–∏–ª–∏ –≥–æ—Å—Ç—Ä—É –∫–∏—à–∫–æ–≤—É —ñ–Ω—Ñ–µ–∫—Ü—ñ—é‚ùóÔ∏è\\n\\n–í–æ–Ω–∏ —ó–ª–∏ —Å—Ç—Ä–∞–≤–∏, —è–∫—ñ —Å–∞–º—ñ –∂ –≥–æ—Ç—É–≤–∞–ª–∏üò≥\\n\\n–ü–æ–¥—Ä–æ–±–∏—Ü—ñ ‚¨ÖÔ∏è',\n",
       "  'ü§© –£ —Å—Ç–æ–ª–∏—Ü—ñ 6 –≤–µ—Ä–µ—Å–Ω—è –≤—ñ–¥–∫—Ä–∏—é—Ç—å –ø–µ—Ä—à—É –≤ –£–∫—Ä–∞—ó–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É –Ω–∞—Å—Ç—ñ–ª—å–Ω–∏—Ö —ñ–≥–æ—Ä\\n\\n–°–ø–æ—á–∞—Ç–∫—É –ø–ª–∞–Ω—É—î—Ç—å—Å—è –ø—Ä–æ–≤–æ–¥–∏—Ç–∏ —ñ–≥—Ä–æ–≤—ñ –∑—É—Å—Ç—Ä—ñ—á—ñ. –¢–∞–∫–æ–∂ —É—Å—ñ –æ—Ö–æ—á—ñ –º–æ–∂—É—Ç—å –±—Ä–∞—Ç–∏ –Ω–∞—Å—Ç—ñ–ª–∫–∏ —É —á–∏—Ç–∞–ª—å–Ω—ñ–π –∑–∞–ª—ñ, –∞ –∑–≥–æ–¥–æ–º —ñ–≥—Ä–∏ –∑–º–æ–∂—É—Ç—å –¥–∞–≤–∞—Ç–∏ –¥–æ–¥–æ–º—É, —è–∫ –∫–Ω–∏–≥–∏.\\n\\n–Ü–≥—Ä–æ–≤–∏–π —Ñ–æ–Ω–¥ –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ –Ω–∞–ª—ñ—á—É—î –ø–æ–Ω–∞–¥ 125 —ñ–≥–æ—Ä. –©–æ–± —Å–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏—Å—è —ñ–≥—Ä–æ–≤–∏–º —Ñ–æ–Ω–¥–æ–º, –ø–æ—Ç—Ä—ñ–±–Ω–æ —Å—Ç–∞—Ç–∏ —á–∏—Ç–∞—á–µ–º –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—ó –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ —ñ–º. –¢. –ì. –®–µ–≤—á–µ–Ω–∫–∞ –¥–ª—è –¥—ñ—Ç–µ–π (–ø—Ä–æ—Å–ø. –ë–µ—Ä–µ—Å—Ç–µ–π—Å—å–∫–∏–π, 25-–ê).\\n\\n–ö–∏—ó–≤ ‚Äî –ø—Ä—è–º–∞ —Ç—Ä–∞–Ω—Å–ª—è—Ü—ñ—è üëà\\n–ù–∞–¥—ñ—Å–ª–∞—Ç–∏ –Ω–æ–≤–∏–Ω—É',\n",
       "  '‚ö°Ô∏è–°—å–æ–≥–æ–¥–Ω—ñ –¥–µ–Ω—å –Ω–∞—Ä–æ–¥–∂–µ–Ω–Ω—è —É –ö–†–ï–©–ê–¢–ò–ö 36 üéâ\\n\\n–ù–∞–º —Å—å–æ–≥–æ–¥–Ω—ñ, 31.08.2023, –≤–∏–ø–æ–≤–Ω—é—î—Ç—å—Å—è —Ä—ñ–≤–Ω–æ 3 —Ä–æ–∫–∏üçæüéä\\n\\n–ö–æ–∂–µ–Ω –¥–µ–Ω—å –Ω–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞ —Ä–æ–±–∏—Ç—å —Ç–∞–∫, —â–æ–± –≤–∞–º –±—É–ª–æ —Ü—ñ–∫–∞–≤–æ —ñ –∫–æ—Ä–∏—Å–Ω–æ –ø—Ä–æ–∂–∏—Ç–∏ —Ü–µ–π –¥–µ–Ω—å, —Ä–æ–∑–∫–∞–∑—É—î —Ö—Ç–æ –Ω–∞—Å–ø—Ä–∞–≤–¥—ñ –∫–µ—Ä—É—î –ö–∏—î–≤–æ–º, —Ö—Ç–æ —ñ —è–∫ –∑–∞—Ä–æ–±–ª—è—î –Ω–∞ –º—ñ—Å—å–∫–æ–º—É –±—é–¥–∂–µ—Ç—ñ, –¥–∞—Ä—É—î–º–æ –∞–Ω–∞–ª—ñ—Ç–∏–∫—É –∫–æ–º—ñ—Å—ñ–π, —Å–µ—Å—ñ–π, —Ä–æ–∑–ø–æ–≤—ñ–¥–∞—î–º–æ –ø—Ä–æ –∑–µ–º–µ–ª—å–Ω–∏–π –¥–µ—Ä–∏–±–∞–Ω, –ø—Ä–æ —Å–º–æ—Ç—Ä—è—â–∏—Ö, –µ–ª—ñ—Ç—É —ñ –±—é–¥–∂–µ—Ç, —Ä–æ–∑–∫—Ä–∏–≤–∞—î–º–æ —Å—Ö–µ–º–∏ —ñ —Ç–∞—î–º–Ω–µ –∂–∏—Ç—Ç—è –ø–æ—Å–∞–¥–æ–≤—Ü—ñ–≤ –≤ —ñ–º º—è –ø—Ä–∞–≤–¥–∏ —ñ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—ñ.\\n\\n–ú–∏ –ª—é–±–∏–º–æ –Ω–∞—à –ö–∏—ó–≤, –∑–Ω–∞—î–º–æ –∫–æ–∂–µ–Ω –∑–∞–∫—É—Ç–æ–∫ –Ω–∞ –•—Ä–µ—â–∞—Ç–∏–∫—É 36 —Ç–∞ –≥–æ–≤–æ—Ä–∏–º–æ —Ç–µ, –ø—Ä–æ —â–æ –≤—Å—ñ –º–æ–≤—á–∞—Ç—å.\\n\\n–®–∞–Ω–æ–≤–Ω—ñ –∫–∏—è–Ω–∏, –ø—Ä–∏—Ö–∏–ª—å–Ω–∏–∫–∏, –±—É–¥–µ–º–æ –≤–¥—è—á–Ω—ñ –≤ —á–µ—Å—Ç—å –ø–æ–¥–∞—Ä—É–Ω–∫—É –¥–æ –Ω–∞—à–æ–≥–æ –¥–Ω—è –Ω–∞—Ä–æ–¥–∂–µ–Ω–Ω—è –∑—Ä–æ–±–∏—Ç–∏ —Ä–µ–ø–æ—Å—Ç, —á–∏ –Ω–∞–ø–∏—Å–∞—Ç–∏ –ø—Ä–æ –Ω–∞—Å –≤—ñ–¥–∑–∏–≤-–ø—Ä–∏–≤—ñ—Ç–∞–Ω–Ω—è —É —Å–≤–æ—î–º—É –ø–æ—Å—Ç—ñ –≤ –§–µ–π—Å–±—É–∫, –Ü–Ω—Å—Ç–∞–≥—Ä–∞–º, –¢—ñ–∫ –¢–æ–∫, –∞–±–æ –¢–µ–ª–µ–≥—Ä–∞–º - –ø–æ—Å—Ç–∞–≤–∏–≤—à–∏ —Ç–µ–≥ #—Ç–µ–ª–µ–≥—Ä–∞–º–∫–∞–Ω–∞–ª–∫—Ä–µ—â–∞—Ç–∏–∫36 —Ç–∞ –ø–æ—Å–∏–ª–∞–Ω–Ω—è https://t.me/khreschatyk36. –ü–æ—Ç—ñ–º –∫–∏–¥–∞–π—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Å–≤—ñ–π –ø–æ—Å—Ç, –∞–±–æ –π–æ–≥–æ —Å–∫—Ä—ñ–Ω—à–æ—Ç –Ω–∞–º –Ω–∞ –ø–æ—à—Ç—É khreschatyk36@protonmail.com —ñ –º–∏ –æ–ø—É–±–ª—ñ–∫—É—î–º–æ –í–∞—à—ñ –¥–æ–±—Ä—ñ —á–∏ –Ω–µ –¥—É–∂–µ —Å–ª–æ–≤–∞, –∞ —Ç–∞–∫–æ–∂ —á–µ—Ä–µ–∑ –Ω–∞–¥—ñ–π–Ω–æ–≥–æ —Ç–∞ –∫–º—ñ—Ç–ª–∏–≤–æ–≥–æ –ø–æ—Å–µ—Ä–µ–¥–Ω–∏–∫–∞ –ø–µ—Ä–µ–¥–∞–º–æ —Å–∏–º–≤–æ–ª—ñ—á–Ω–∏–π –ø—Ä–µ–∑–µ–Ω—Çü•≥\\n\\nP.S. –ó–∞–ø—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω—ñ –ª–∏—Å—Ç—ñ–≤–∫–∏ –º–æ–∂–µ—Ç–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –¥–ª—è —Å–≤–æ—ó—Ö –ø–æ—Å—Ç—ñ–≤, —á–∏ —Ä–æ–±—ñ—Ç—å —Å–≤–æ—ó, –±–∞–∂–∞–Ω–æ —Å–º—ñ—à–Ω—ñ—à—ñüòÖ\\n\\n–Ü —Ü–µ–π, –º–æ–∂–µ—Ç–µ –∑–∞–¥–æ–Ω–∞—Ç–∏—Ç–∏ –¥–ª—è –ó–°–£ –Ω–∞ —Ç–æ–≥–æ, –∫–æ–º—É –¥–æ–≤—ñ—Ä—è—î—Ç–µüá∫üá¶\\n\\n–Ü –ø—ñ–¥–ø–∏—Å—É–π—Ç–µ—Å—å, —Ö—Ç–æ —â–µ —Ü—å–æ–≥–æ –Ω–µ –∑—Ä–æ–±–∏–≤:\\n@khreschatyk36']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_data = {'texts': test_dataset['text'].sample(5).to_list()}\n",
    "request_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c28b8218-dd11-4a7e-acf9-7f426ee50c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\"–ú–∏–∫–æ–ª–∞\"],[],[\"–ö–∏—î–≤—ñ\"],[\"–£–∫—Ä–∞—ó–Ω—ñ\",\"–ö–∏—ó–≤\"],[\"–ö–∏—ó–≤\"]]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post('http://localhost:8088/extract_locations', json=request_data).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb1266-e562-4d41-9f13-f3dcb7f47c00",
   "metadata": {},
   "source": [
    "As we can see, distilled model misses a lot of locations and mostly predicts obvious ones: \"–ö–∏—ó–≤...\", \"–£–∫—Ä–∞—ó–Ω–∞\", etc.\n",
    "\n",
    "This is probably happens because distilled model was trained on very small dataset and didn't see a lot of rare locations.\n",
    "\n",
    "To solve this, model should be trained on bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40611beb-b9a1-48a8-9050-b6ce5fb9f0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
