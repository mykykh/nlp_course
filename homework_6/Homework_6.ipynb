{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iSjFDO2cNSe7",
   "metadata": {
    "id": "iSjFDO2cNSe7"
   },
   "source": [
    "# Translation english to ukrainian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "voGBHJm-pio4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voGBHJm-pio4",
    "outputId": "3c261bc1-a078-42b4-f8cc-066baa01d190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.41.1)\n",
      "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu118)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers peft evaluate sacrebleu accelerate bitsandbytes bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d46c12-5829-4430-bec9-f43c532030cf",
   "metadata": {
    "id": "d0d46c12-5829-4430-bec9-f43c532030cf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator\n",
    "from peft import get_peft_model, get_peft_config, PrefixTuningConfig, TaskType, LoraConfig, PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DOLLdl3nN4ya",
   "metadata": {
    "id": "DOLLdl3nN4ya"
   },
   "source": [
    "## Selecting model\n",
    "Using nllb because it was pretrained on 100+ languages and knows ukrainian tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f22fc0-5f59-48f9-9169-e83b22bd4b9a",
   "metadata": {
    "id": "31f22fc0-5f59-48f9-9169-e83b22bd4b9a"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'opus100'\n",
    "model_name = 'facebook/nllb-200-distilled-600M'\n",
    "model_save_path = 'en-uk-nllb/'\n",
    "max_length = 32\n",
    "batch_size = 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zk-be4KFN_VI",
   "metadata": {
    "id": "zk-be4KFN_VI"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb934d27-7267-469b-8722-d0805ce5d962",
   "metadata": {
    "id": "eb934d27-7267-469b-8722-d0805ce5d962"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(dataset_name, 'en-uk', split='train[:2%]')\n",
    "test_dataset = load_dataset(dataset_name, 'en-uk', split='test')\n",
    "validation_dataset = load_dataset(dataset_name, 'en-uk', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b505ec09-99ca-4576-8afc-3dbefac26888",
   "metadata": {
    "id": "b505ec09-99ca-4576-8afc-3dbefac26888"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qLgwpstPOVBm",
   "metadata": {
    "id": "qLgwpstPOVBm"
   },
   "source": [
    "## Vectorizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ff56f7-2d16-43e0-91e6-6d7c42504a02",
   "metadata": {
    "id": "31ff56f7-2d16-43e0-91e6-6d7c42504a02"
   },
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    input = [e['en'] for e in examples['translation']]\n",
    "    target = [e['uk'] for e in examples['translation']]\n",
    "    input = tokenizer(input, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    target = tokenizer(target, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt').input_ids\n",
    "    target[target == tokenizer.pad_token_id] = -100\n",
    "    input['labels'] = target\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6e042f-8bef-4c8d-bbc5-0c1b4782daf7",
   "metadata": {
    "id": "8b6e042f-8bef-4c8d-bbc5-0c1b4782daf7"
   },
   "outputs": [],
   "source": [
    "processed_train_dataset = train_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "processed_test_dataset = test_dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "az3mMR4QiBhZ",
   "metadata": {
    "id": "az3mMR4QiBhZ"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    processed_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    processed_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=False, # don't shuffle to calculate metrics\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0vlbkN2SOvRn",
   "metadata": {
    "id": "0vlbkN2SOvRn"
   },
   "source": [
    "## Lora config\n",
    "Using LoRA because it saves gpu memory and has much better score then prefix tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "630dVTbngOUZ",
   "metadata": {
    "id": "630dVTbngOUZ"
   },
   "outputs": [],
   "source": [
    "prefix_config = PrefixTuningConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    num_virtual_tokens=100\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    target_modules=['q_proj', 'v_proj'],\n",
    "    bias='none',\n",
    "    task_type='SEQ_2_SEQ_LM'\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "# model = get_peft_model(model, prefix_config)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1KwANw7nPCkT",
   "metadata": {
    "id": "1KwANw7nPCkT"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "OkkNqdRQwsTn",
   "metadata": {
    "id": "OkkNqdRQwsTn"
   },
   "outputs": [],
   "source": [
    "bleu = evaluate.load('bleu')\n",
    "chrf = evaluate.load('chrf')\n",
    "bert = evaluate.load('bertscore')\n",
    "references = [e['uk'] for e in test_dataset['translation']]\n",
    "def compute_metrics(model):\n",
    "  model.eval()\n",
    "  eval_loss = 0\n",
    "  eval_preds = []\n",
    "\n",
    "  for eval_batch in test_dataloader:\n",
    "    eval_batch = {k: v.to(device) for k, v in eval_batch.items()}\n",
    "    with torch.no_grad():\n",
    "      out = model(**eval_batch)\n",
    "    eval_loss += out.loss.detach().cpu().item()\n",
    "    eval_preds.extend(\n",
    "        tokenizer.batch_decode(\n",
    "            torch.argmax(out.logits, -1).detach().cpu().numpy(),\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "  bleu_score = bleu.compute(predictions=eval_preds, references=references)['bleu']\n",
    "  chrf_score = chrf.compute(predictions=eval_preds, references=references)['score']\n",
    "  bert_score = bert.compute(predictions=eval_preds, references=references, lang='uk')\n",
    "  bert_f1 = np.mean(bert_score['f1'])\n",
    "\n",
    "  return eval_loss / len(test_dataloader), bleu_score, chrf_score, bert_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TI_hqABlPMdO",
   "metadata": {
    "id": "TI_hqABlPMdO"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "IjJ5CDh-wGno",
   "metadata": {
    "id": "IjJ5CDh-wGno"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "_8_RoFJeivkC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "_8_RoFJeivkC",
    "outputId": "fee37f5a-bf88-4af7-9a1e-065eec51cd9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 200/625 [03:17<1:34:58, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 200, train loss: 2.4943442064523698, test loss: 2.1185390646495517, bleu: 0.16230913081816817, chtf: 40.1785590147101, bert: 0.7864089741408825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 400/625 [06:26<41:39, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 400, train loss: 2.1118676936626435, test loss: 2.0991179621408858, bleu: 0.17170187669657797, chtf: 40.629937145397385, bert: 0.7936508451998234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 600/625 [09:34<04:29, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: 600, train loss: 2.0796703481674195, test loss: 2.0881263396096608, bleu: 0.180446705133743, chtf: 41.010826436402176, bert: 0.7974831014275551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [09:53<00:00,  1.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-699077cd-b2a0-4b1d-a387-1a5d7bfcb248\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>chrf_score</th>\n",
       "      <th>bert_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2.494344</td>\n",
       "      <td>2.118539</td>\n",
       "      <td>0.162309</td>\n",
       "      <td>40.178559</td>\n",
       "      <td>0.786409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400.0</td>\n",
       "      <td>2.111868</td>\n",
       "      <td>2.099118</td>\n",
       "      <td>0.171702</td>\n",
       "      <td>40.629937</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600.0</td>\n",
       "      <td>2.079670</td>\n",
       "      <td>2.088126</td>\n",
       "      <td>0.180447</td>\n",
       "      <td>41.010826</td>\n",
       "      <td>0.797483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-699077cd-b2a0-4b1d-a387-1a5d7bfcb248')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-699077cd-b2a0-4b1d-a387-1a5d7bfcb248 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-699077cd-b2a0-4b1d-a387-1a5d7bfcb248');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a6d17e54-5d98-4a0b-8542-840498d131ad\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6d17e54-5d98-4a0b-8542-840498d131ad')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a6d17e54-5d98-4a0b-8542-840498d131ad button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    step  train_loss  test_loss  bleu_score  chrf_score   bert_f1\n",
       "0  200.0    2.494344   2.118539    0.162309   40.178559  0.786409\n",
       "1  400.0    2.111868   2.099118    0.171702   40.629937  0.793651\n",
       "2  600.0    2.079670   2.088126    0.180447   41.010826  0.797483"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_steps = 200\n",
    "results_df = pd.DataFrame({\n",
    "    'step': [],\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'bleu_score': [],\n",
    "    'chrf_score': [],\n",
    "    'bert_f1': []\n",
    "    })\n",
    "train_loss = 0\n",
    "\n",
    "model.train()\n",
    "for step, batch in enumerate(tqdm(train_dataloader), start=1):\n",
    "  batch = {k: v.to(device) for k, v in batch.items()}\n",
    "  out = model(**batch)\n",
    "  loss = out.loss\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  train_loss += loss.detach().cpu().item()\n",
    "\n",
    "  if step % eval_steps == 0:\n",
    "    test_loss, bleu_score, chtf_score, bert_f1 = compute_metrics(model)\n",
    "    metrics = [\n",
    "        step,\n",
    "        train_loss/eval_steps,\n",
    "        test_loss,\n",
    "        bleu_score,\n",
    "        chtf_score,\n",
    "        bert_f1\n",
    "    ]\n",
    "\n",
    "    results_df.loc[len(results_df)] = metrics\n",
    "    print(f'\\nStep: {metrics[0]}, train loss: {metrics[1]}, test loss: {metrics[2]}, bleu: {metrics[3]}, chtf: {metrics[4]}, bert: {metrics[5]}')\n",
    "\n",
    "    train_loss = 0\n",
    "    model.save_pretrained(model_save_path + f'step-{step}')\n",
    "    scheduler.step()\n",
    "    model.train()\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x0a91cTIPVie",
   "metadata": {
    "id": "x0a91cTIPVie"
   },
   "source": [
    "## Inference\n",
    "Comparing original and trained model. Loading model in 8bit to save gpu memory and do faster predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "VoypGy6ownSk",
   "metadata": {
    "id": "VoypGy6ownSk"
   },
   "outputs": [],
   "source": [
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, load_in_8bit=True)\n",
    "trained_model = PeftModel.from_pretrained(original_model, model_save_path + 'step-600')\n",
    "trained_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd952b35-49c9-4ac4-ad62-da100f118d19",
   "metadata": {
    "id": "dd952b35-49c9-4ac4-ad62-da100f118d19"
   },
   "outputs": [],
   "source": [
    "examples = pd.DataFrame(validation_dataset['translation']).sample(5)['en'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "513ed301-3ff3-4d45-8e71-e88dbc93236b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "513ed301-3ff3-4d45-8e71-e88dbc93236b",
    "outputId": "7eadf75d-ab86-4747-e22b-fd1ebdb6b1de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 I got $500.\n",
      "Original model translation: \n",
      "У меня есть 500 долларов.\n",
      "Trained model translation: \n",
      "У мене 500 доларів.\n",
      "2 And there is one more thing, Mr Briggs.\n",
      "Original model translation: \n",
      "И еще одна вещь, мистер Бригггс.\n",
      "Trained model translation: \n",
      "І є ще одне, містер Бріггс.\n",
      "3 But it's here, it's getting in.\n",
      "Original model translation: \n",
      "Но он здесь, он входит.\n",
      "Trained model translation: \n",
      "Но он здесь, он входит.\n",
      "4 Make sure that so duplicate symbol exists already in the row/ column/ section you are entering it to.\n",
      "Original model translation: \n",
      "Убедитесь, что символы, которые вы вводят в строку/ столб/ раздел, уже имеются.\n",
      "Trained model translation: \n",
      "Перевіртесь, що такий дубликаційний символ вже існує в строці/ колоні/ розділі, в який ви його вводите.\n",
      "5 That was hard to believe.\n",
      "Original model translation: \n",
      "Это было трудно поверить.\n",
      "Trained model translation: \n",
      "В это было трудно поверить.\n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(examples, start=1):\n",
    "  print(f'{i} {example}')\n",
    "  example_for_original = tokenizer(example, return_tensors='pt').input_ids.to(device)\n",
    "  example_for_trained = tokenizer(example, return_tensors='pt').input_ids.to(device)\n",
    "  original_translation = tokenizer.decode(\n",
    "      original_model.generate(input_ids=example_for_original, forced_bos_token_id=tokenizer.lang_code_to_id['rus_Cyrl'], max_new_tokens=100)[0],\n",
    "      skip_special_tokens=True\n",
    "  )\n",
    "  trained_translation = tokenizer.decode(\n",
    "      trained_model.generate(input_ids=example_for_trained, max_new_tokens=100)[0],\n",
    "      skip_special_tokens=True\n",
    "  )\n",
    "  print('Original model translation: ')\n",
    "  print(original_translation)\n",
    "  print(\"Trained model translation: \")\n",
    "  print(trained_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mGtFtGF08I59",
   "metadata": {
    "id": "mGtFtGF08I59"
   },
   "source": [
    "As we can see, model after training can translate english sentences into ukrainian even without adding forced_bos_token_id.\n",
    "Also, sometimes model can translate into russian, it probably happens because original nllb model wasn't trained on ukrainian and it tries to translate into closest language it knows. This can be solved by training model longer.\n",
    "\n",
    "As for different metrics: bleu, chrF and bert score are all increasing by similar proportion, the difference is absolute score.\n",
    "This means that all metrics can be used interchangeably. But I think that chrF shows score that, in absolute value, better correlates with model performance.\n",
    "\n",
    "The problem with the bleu metric is that it matches whole tokens and penilizes when model uses correct word in incorrect form. As we can see from predicted examples, model can succesfully translate overall sentence meaning, but makes some mistakes in used words. This means that bleu score underestimates model performance.\n",
    "\n",
    "The problem with bert score is that, while it much better estimates similar meaning of sentence, it doesn't pay much attention to word spelling. And since russian and ukrainian have similar spelling for many words, this causes bert to not recognize that model correctly translates sentence, but into the wrong language. And since biggest problem with model is that it translates into russian and not ukrainian, bert overestimates model performance.\n",
    "\n",
    "On the other hand, chrF calculates all character and word n-grams matches. That alows this metric to evaluate word spelling, while beeing less sensetive to smaller mistakes. And from predicted examples we can see that model translates into russian about half of the sentences and makes some mistakes in ukrainian translations. Therefore we can estimate model score at about 40%, which is similar to chrF evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03478e6-bec4-4864-a40a-13ce3d537808",
   "metadata": {
    "id": "c03478e6-bec4-4864-a40a-13ce3d537808"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
